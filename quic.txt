 ABSTRACT
 Wepresent our experience with QUIC, an encrypted, multiplexed,
 and low-latency transport protocol designed from the ground up to
 improve transport performance for HTTPS traffic and to enable rapid
 deployment and continued evolution of transport mechanisms. QUIC
 has been globally deployed at Google on thousands of servers and
 is used to serve traffic to a range of clients including a widely-used
 web browser (Chrome) and a popular mobile video streaming app
 (YouTube). We estimate that 7% of Internet traffic is now QUIC. We
 describe our motivations for developing a new transport, the princi
ples that guided our design, the Internet-scale process that we used
 to perform iterative experiments on QUIC, performance improve
ments seen by our various services, and our experience deploying
 QUIC globally. We also share lessons about transport design and the
 Internet ecosystem that we learned from our deployment.
 CCSCONCEPTS
 • Networks → Network protocol design; Transport protocols;
 Cross-layer protocols;
 ACMReference format:
 Adam Langley, Alistair Riddoch, Alyssa Wilk, Antonio Vicente, Charles
 Krasic, Dan Zhang, Fan Yang, Fedor Kouranov, Ian Swett, Janardhan Iyengar,
 Jeff Bailey, Jeremy Dorfman, Jim Roskind, Joanna Kulik, Patrik Westin,
 Raman Tenneti, Robbie Shade, Ryan Hamilton, Victor Vasiliev, Wan-Teh
 Chang, Zhongyi Shi . 2017. The QUIC Transport Protocol: Design and
 Internet-Scale Deployment. In Proceedings of SIGCOMM ’17, Los Angeles,
 CA, USA, August 21-25, 2017, 14 pages.
 https://doi.org/10.1145/3098822.3098842
 1 INTRODUCTION
 We present QUIC, a new transport designed from the ground up
 to improve performance for HTTPS traffic and to enable rapid de
ployment and continued evolution of transport mechanisms. QUIC
 replaces most of the traditional HTTPS stack: HTTP/2, TLS, and
 *Fedor Kouranov is now at Yandex, and Jim Roskind is now at Amazon. Author names
 are in alphabetical order.
 Permission to make digital or hard copies of part or all of this work for personal or
 classroom use is granted without fee provided that copies are not made or distributed
 for profit or commercial advantage and that copies bear this notice and the full citation
 on the first page. Copyrights for third-party components of this work must be honored.
 For all other uses, contact the owner/author(s).
 SIGCOMM’17, August 21-25, 2017, Los Angeles, CA, USA
 ©2017 Copyright held by the owner/author(s).
 ACMISBN978-1-4503-4653-5/17/08.
 https://doi.org/10.1145/3098822.3098842
 Figure 1: QUIC in the traditional HTTPS stack.
 TCP (Figure 1). We developed QUIC as a user-space transport with
 UDP as a substrate. Building QUIC in user-space facilitated its
 deployment as part of various applications and enabled iterative
 changes to occur at application update timescales. The use of UDP
 allows QUIC packets to traverse middleboxes. QUIC is an encrypted
 transport: packets are authenticated and encrypted, preventing mod
ification and limiting ossification of the protocol by middleboxes.
 QUIC uses a cryptographic handshake that minimizes handshake
 latency for most connections by using known server credentials on
 repeat connections and by removing redundant handshake-overhead
 at multiple layers in the network stack. QUIC eliminates head-of-line
 blocking delays by using a lightweight data-structuring abstraction,
 streams, which are multiplexed within a single connection so that
 loss of a single packet blocks only streams with data in that packet.
 On the server-side, our experience comes from deploying QUIC
 at Google’s front-end servers, which collectively handle billions of
 requests a day from web browsers and mobile apps across a wide
 range of services. On the client side, we have deployed QUIC in
 Chrome, in our mobile video streaming YouTube app, and in the
 Google Search app on Android. We find that on average, QUIC re
duces latency of Google Search responses by 8.0% for desktop users
 and by 3.6% for mobile users, and reduces rebuffer rates of YouTube
 playbacks by 18.0% for desktop users and 15.3% for mobile users1.
 As shown in Figure 2, QUIC is widely deployed: it currently ac
counts for over 30% of Google’s total egress traffic in bytes and
 consequently an estimated 7% of global Internet traffic [61].
 Welaunched an early version of QUIC as an experiment in 2013.
 After several iterations with the protocol and following our de
ployment experience over three years, an IETF working group was
 formed to standardize it [2]. QUIC is a single monolithic protocol in
 1Throughout this paper "desktop" refers to Chrome running on desktop platforms
 (Windows, Mac, Linux, etc.) and "mobile" refers to apps running on Android devices.
 183
SIGCOMM’17, August 21-25, 2017, Los Angeles, CA, USA
 A. Langley et al.
 Figure 2: Timeline showing the percentage of Google traffic served over
 QUIC. Significant increases and decreases are described in Section 5.1.
 Figure 3: Increase in secure web traffic to Google’s front-end servers.
 our current deployment, but IETF standardization will modularize
 it into constituent parts. In addition to separating out and specify
ing the core protocol [33, 34], IETF work will describe an explicit
 mapping of HTTP on QUIC [9] and separate and replace QUIC’s
 cryptographic handshake with the more recent TLS 1.3 [55, 63].
 This paper describes pre-IETF QUIC design and deployment. While
 details of the protocol will change through IETF deliberation, we
 expect its core design and performance to remain unchanged.
 In this paper, we often interleave our discussions of the protocol,
 its use in the HTTPS stack, and its implementation. These three are
 deeply intertwined in our experience. The paper attempts to reflect
 this connectedness without losing clarity.
 2 MOTIVATION:WHYQUIC?
 Growth in latency-sensitive web services and use of the web as a plat
form for applications is placing unprecedented demands on reducing
 web latency. Web latency remains an impediment to improving user
experience [21, 25], and tail latency remains a hurdle to scaling the
 web platform [15]. At the same time, the Internet is rapidly shifting
 from insecure to secure traffic, which adds delays. As an example
 of a general trend, Figure 3 shows how secure web traffic to Google
 has increased dramatically over a short period of time as services
 have embraced HTTPS. Efforts to reduce latency in the underlying
 transport mechanisms commonly run into the following fundamental
 limitations of the TLS/TCP ecosystem.
 Protocol Entrenchment: While new transport protocols have been
 specified to meet evolving application demands beyond TCP’s sim
ple service [40, 62], they have not seen wide deployment [49, 52, 58].
 Middleboxes have accidentally become key control points in the In
ternet’s architecture: firewalls tend to block anything unfamiliar for
 security reasons and Network Address Translators (NATs) rewrite
 the transport header, making both incapable of allowing traffic from
 new transports without adding explicit support for them. Any packet
 content not protected by end-to-end security, such as the TCP packet
 header, has become fair game for middleboxes to inspect and mod
ify. As a result, even modifying TCP remains challenging due to
 its ossification by middleboxes [29, 49, 54]. Deploying changes to
 TCP has reached a point of diminishing returns, where simple pro
tocol changes are now expected to take upwards of a decade to see
 significant deployment (see Section 8).
 ImplementationEntrenchment:AstheInternetcontinuestoevolve
 and as attacks on various parts of the infrastructure (including the
 transport) remain a threat, there is a need to be able to deploy changes
 to clients rapidly. TCP is commonly implemented in the Operat
ing System (OS) kernel. As a result, even if TCP modifications
 were deployable, pushing changes to TCP stacks typically requires
 OSupgrades. This coupling of the transport implementation to the
 OSlimits deployment velocity of TCP changes; OS upgrades have
 system-wide impact and the upgrade pipelines and mechanisms are
 appropriately cautious [28]. Even with increasing mobile OS popula
tions that have more rapid upgrade cycles, sizeable user populations
 often end up several years behind. OS upgrades at servers tend to
 be faster by an order of magnitude but can still take many months
 because of appropriately rigorous stability and performance testing
 of the entire OS. This limits the deployment and iteration velocity
 of even simple networking changes.
 Handshake Delay: The generality of TCP and TLS continues to
 serve Internet evolution well, but the costs of layering have become
 increasingly visible with increasing latency demands on the HTTPS
 stack. TCP connections commonly incur at least one round-trip delay
 of connection setup time before any application data can be sent,
 and TLS adds two round trips to this delay2. While network band
width has increased over time, the speed of light remains constant.
 Most connections on the Internet, and certainly most transactions on
 the web, are short transfers and are most impacted by unnecessary
 handshake round trips.
 Head-of-line Blocking Delay: Toreducelatency and overhead costs
 of using multiple TCP connections, HTTP/1.1 recommends limiting
 the number of connections initiated by a client to any server [19].
 To reduce transaction latency further, HTTP/2 multiplexes multi
ple objects and recommends using a single TCP connection to any
 server [8]. TCP’s bytestream abstraction, however, prevents applica
tions from controlling the framing of their communications [12] and
 imposes a "latency tax" on application frames whose delivery must
 wait for retransmissions of previously lost TCP segments.
 In general, the deployment of transport modifications for the
 web requires changes to web servers and clients, to the transport
 stack in server and/or client OSes, and often to intervening mid
dleboxes. Deploying changes to all three components requires in
centivizing and coordinating between application developers, OS
 vendors, middlebox vendors, and the network operators that deploy
 these middleboxes. QUIC encrypts transport headers and builds
 transport functions atop UDP, avoiding dependence on vendors and
 network operators and moving control of transport deployment to
 the applications that directly benefit from them.